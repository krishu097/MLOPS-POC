name: MLOps Pipeline

on:
  push:
    branches: [main]
    paths: ['data.csv', 'code/**']
  workflow_dispatch:
    inputs:
      trigger_reason:
        description: 'Reason for triggering training'
        required: false
        default: 'Manual trigger'
      data_path:
        description: 'S3 path to training data'
        required: false
        default: 's3://bucket/training-data/data.csv'

env:
  AWS_REGION: us-east-2
  S3_BUCKET: ${{ vars.S3_BUCKET }}

jobs:
  train:
    runs-on: ubuntu-latest
    permissions:
      id-token: write
      contents: read
    outputs:
      model-uri: ${{ steps.training.outputs.model-uri }}
      accuracy: ${{ steps.training.outputs.accuracy }}
      f1-score: ${{ steps.training.outputs.f1-score }}
    steps:
      - uses: actions/checkout@v4
      
      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ secrets.AWS_DEPLOYMENT_ROLE_ARN }}
          aws-region: ${{ env.AWS_REGION }}
      
      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.9'
      
      - name: Install dependencies
        run: |
          pip install boto3 sagemaker pandas scikit-learn joblib numpy
      
      - name: Download training data from S3
        run: |
          # Use data path from trigger or default
          DATA_PATH="${{ github.event.inputs.data_path || 'data.csv' }}"
          if [[ $DATA_PATH == s3://* ]]; then
            aws s3 cp "$DATA_PATH" data.csv
          fi
        env:
          AWS_DEFAULT_REGION: ${{ env.AWS_REGION }}
      
      - name: Train Model
        id: training
        run: |
          python code/train.py --data-file data.csv --output-dir ./model
          
          # Extract metrics for outputs
          ACCURACY=$(python -c "import json; print(json.load(open('./model/metrics.json'))['accuracy'])")
          F1_SCORE=$(python -c "import json; print(json.load(open('./model/metrics.json'))['f1_score'])")
          
          echo "accuracy=$ACCURACY" >> $GITHUB_OUTPUT
          echo "f1-score=$F1_SCORE" >> $GITHUB_OUTPUT
          echo "model-uri=./model/model.pkl" >> $GITHUB_OUTPUT
        
      - name: Get ECR Repository URL
        id: ecr
        run: |
          ECR_URL=$(aws ecr describe-repositories --repository-names mlops-loan-prediction --query 'repositories[0].repositoryUri' --output text)
          echo "ecr-url=$ECR_URL" >> $GITHUB_OUTPUT
        env:
          AWS_DEFAULT_REGION: ${{ env.AWS_REGION }}
      
      - name: Build and Push Docker Image
        run: |
          # Get ECR login
          aws ecr get-login-password --region ${{ env.AWS_REGION }} | docker login --username AWS --password-stdin ${{ steps.ecr.outputs.ecr-url }}
          
          # Build image with trained model
          docker build -t mlops-model:v${{ github.run_number }} .
          docker tag mlops-model:v${{ github.run_number }} ${{ steps.ecr.outputs.ecr-url }}:v${{ github.run_number }}
          
          # Push to ECR
          docker push ${{ steps.ecr.outputs.ecr-url }}:v${{ github.run_number }}
        env:
          AWS_DEFAULT_REGION: ${{ env.AWS_REGION }}

  deploy:
    needs: train
    if: needs.train.outputs.accuracy >= '0.7' && needs.train.outputs.f1-score >= '0.7'
    runs-on: ubuntu-latest
    permissions:
      id-token: write
      contents: read
    steps:
      - uses: actions/checkout@v4
      
      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ secrets.AWS_DEPLOYMENT_ROLE_ARN }}
          aws-region: ${{ env.AWS_REGION }}
      
      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.9'
      
      - name: Install dependencies
        run: |
          pip install boto3 sagemaker
      
      - name: Deploy Model
        run: |
          python .github/workflows/deploy_model.py
        env:
          MODEL_URI: ${{ needs.train.outputs.model-uri }}
          S3_BUCKET: ${{ env.S3_BUCKET }}